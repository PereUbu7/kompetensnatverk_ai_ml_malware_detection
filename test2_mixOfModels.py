import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.python.ops import variables
from tensorflow.python.framework import dtypes

X_data = np.arange(100, step=.1)
y_data = X_data + 20 * np.sin(X_data/10)

n_samples = 1000
batch_size = 1000
n_of_experts = 5

X_test_data = np.arange(100, step=100/batch_size)

X_data = np.reshape(X_data, (n_samples,1))
X_test_data = np.reshape(X_test_data, (batch_size,1))
y_data = np.reshape(y_data, (n_samples,1))

X = tf.placeholder(tf.float32, shape=(batch_size, 1))
y = tf.placeholder(tf.float32, shape=(batch_size, 1))

manager_layer1 = tf.contrib.layers.fully_connected(
    X,
    n_of_experts,
    activation_fn=tf.nn.relu,
    normalizer_fn=None,
    normalizer_params=None,
    weights_initializer=tf.initializers.random_normal(stddev=0.1),
    weights_regularizer=None,
    biases_initializer=tf.zeros_initializer(1),
    biases_regularizer=None,
    reuse=None,
    variables_collections=None,
    outputs_collections=None,
    trainable=True,
    scope=None
)

manager = tf.contrib.layers.fully_connected(
    manager_layer1,
    n_of_experts,
    activation_fn=tf.nn.softmax,
    normalizer_fn=None,
    normalizer_params=None,
    weights_initializer=tf.initializers.random_normal(stddev=0.1),
    weights_regularizer=None,
    biases_initializer=tf.zeros_initializer(1),
    biases_regularizer=None,
    reuse=None,
    variables_collections=None,
    outputs_collections=None,
    trainable=True,
    scope=None
)

experts = tf.contrib.layers.fully_connected(
    X,
    num_outputs=n_of_experts,
    activation_fn=None,
    normalizer_fn=None,
    normalizer_params=None,
    weights_initializer=tf.initializers.random_normal(stddev=0.1),
    weights_regularizer=None,
    biases_initializer=tf.zeros_initializer(1),
    biases_regularizer=None,
    reuse=None,
    variables_collections=None,
    outputs_collections=None,
    trainable=True,
    scope=None
)

# tf.zeros_initializer(),

output = experts*manager
output_sum = tf.reduce_sum(experts*manager, axis=1)

print("output:", output)

residual2 = tf.square(y - experts)

print(residual2)
print(manager)

outcome = residual2*manager

outcome = tf.reduce_sum(outcome, axis=1)

print(outcome)

loss = tf.reduce_sum(outcome)

global_step = variables.Variable(0, dtype=dtypes.int64)

opt_operation = tf.train.RMSPropOptimizer(learning_rate=0.01).minimize(loss)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    loss_array = []

    n_of_steps = 40000

    for i in range(n_of_steps):
        indices = np.random.choice(n_samples, batch_size)
        X_batch, y_batch = X_data[indices], y_data[indices]

        _, loss_val = sess.run([opt_operation, loss], feed_dict={X: X_batch, y: y_batch})

        loss_array.append(loss_val)

        if i%1000 == 0 and i != 0:
            print("Step:", i, "of", n_of_steps)
            res, res_sum = sess.run([output, output_sum], feed_dict={X: X_test_data})

            # Clear last plot
            plt.clf()
            plt.plot(X_data, y_data, '-')
            #plt.plot(X_test_data, np.squeeze(res))
            plt.plot(X_test_data, np.squeeze(res_sum), '.')
            plt.show(block=False)
            plt.pause(0.001)


    plt.show()

    res = sess.run([output], feed_dict={X: X_test_data})

    # plt.plot(loss_array)
    # plt.show()

    plt.plot(X_data, y_data, '-')
    plt.plot(X_test_data, np.squeeze(res))
    plt.plot(X_test_data, np.squeeze(res_sum), '*')
    plt.show()
